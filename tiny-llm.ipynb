{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data/wiki/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass --compile=False if you are GPU poor like me and use free colab GPUs\n",
    "!python train.py config/train_wiki.py --compile=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sample.py --out_dir=out-wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are training probably around 1.5B tokens. This is 1% of what you need to train GPT-2. We will see if it works. I trained the model on 0.1% of the data and it took maybe 10 minutes to train. Back of the envelope calculation we might need up to 10 days running on this mac GPU to fully digest 2.5B. If we were in a RTX 4090 we could cut this time by 10-20x.\n",
    "\n",
    "Calculation. It took ~30 seconds to train on 0.1% of the data. That means 300,000 seconds or ~83 hours, ~3.5 days. This could be trained in 4-8 hours in a modern RTX giving 1TB/s vs mac 100GB/s, fp32 80 TFlops vs M2 Metal GPU 3.6 TFlops. So 10x more bandwidth and 20x more Flops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
